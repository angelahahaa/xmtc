{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os,re,datetime\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from models import get_model\n",
    "from tools.MyClock import MyClock\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "clk = MyClock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'xmlcnn'\n",
    "IN_DIR = 'data/dl_sic'\n",
    "# IN_DIR = 'data/dl_amazon_1'\n",
    "# MODEL_DIR = 'xmlcnn/amazon_model3.h5'\n",
    "MODEL_DIR = 'xmlcnn/sic_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ DATA...\n"
     ]
    }
   ],
   "source": [
    "in_dirs = {\n",
    "    'embedding_matrix':'embedding_matrix.npy',\n",
    "    'x_train':'x_train.npy',\n",
    "    'x_test':'x_test.npy',\n",
    "    'y_train':'y_train.npz',\n",
    "    'y_test':'y_test.npz'\n",
    "}\n",
    "for key,val in in_dirs.items():\n",
    "    d = os.path.join(IN_DIR,val)\n",
    "    if not os.path.exists(d):\n",
    "        raise Exception('path does not exist: {}'.format(d))\n",
    "    else:\n",
    "        in_dirs[key] = d\n",
    "print('READ DATA...')\n",
    "embedding_matrix = np.load(in_dirs['embedding_matrix'])\n",
    "x_test = np.load(in_dirs['x_test'])\n",
    "y_test = scipy.sparse.load_npz(in_dirs['y_test'])\n",
    "y_test = y_test.todense()\n",
    "labels_dim = y_test.shape[-1]\n",
    "num_words,embedding_dim = embedding_matrix.shape\n",
    "max_sequence_length = x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 21:22:59.847549 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 21:22:59.868210 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 21:23:00.147978 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 21:23:00.162779 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0715 21:23:00.220037 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0715 21:23:00.225882 139828792592192 deprecation.py:506] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(MODEL_NAME,embedding_matrix,max_sequence_length,labels_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 21:23:00.307398 139828792592192 deprecation_wrapper.py:119] From /home/angela/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% 04:33\r"
     ]
    }
   ],
   "source": [
    "batch_size = x_test.shape[0]//100#1000\n",
    "k=10\n",
    "inds = []\n",
    "probs = []\n",
    "s = x_test.shape[0]\n",
    "clk.tic()\n",
    "for i,start in enumerate(range(0,s,batch_size)):\n",
    "    end = min(start+batch_size,s)\n",
    "    x_batch = x_test[start:end,:]\n",
    "    out_probs = model.predict(x_batch)\n",
    "    ind = np.argsort(out_probs,axis=1)[:,-k:]\n",
    "    ind = ind[:,::-1]\n",
    "    probs.append(np.take_along_axis(out_probs, ind, axis=1))\n",
    "    inds.append(ind)\n",
    "    print('{:0.0f}% {}'.format(end/s*100,clk.toc(False)),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = 'xmlcnn/amazon3_ind.txt'\n",
    "with open(INDEX_DIR,'ab') as f:\n",
    "    for ind in inds:\n",
    "        np.savetxt(f,ind,fmt='%d')\n",
    "PROB_DIR = 'xmlcnn/amazon3_prob.txt'\n",
    "with open(PROB_DIR,'ab') as f:\n",
    "    for prob in probs:\n",
    "        np.savetxt(f,prob,fmt='%1.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get p@5 (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR: 190722_204831_xmlcnn, p@5: 0.7466\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = 'data/dl_sic'\n",
    "MODEL_DIRS = [\n",
    "    'outputs/190722_204831_xmlcnn',\n",
    "#     'outputs/190715_215817_attentionxml',\n",
    "#     'outputs/190715_235041_attention',\n",
    "]\n",
    "\n",
    "y_test = scipy.sparse.load_npz(os.path.join(IN_DIR,'y_test.npz'))\n",
    "y_test = np.argmax(y_test.todense(),axis=1).A1\n",
    "k=5\n",
    "for MODEL_DIR in MODEL_DIRS:\n",
    "    IND_DIR = os.path.join(MODEL_DIR,'prediction_10_ind.txt')\n",
    "    pred = np.loadtxt(IND_DIR)[:,:k].astype(int)\n",
    "    correct = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y in pred[i,:]:\n",
    "            correct+=1\n",
    "    print('DIR: {}, p@{}: {:.4f}'.format(MODEL_DIR.split('/')[-1],k,correct/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
